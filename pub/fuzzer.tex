% vim: spell
\documentclass[10pt]{sigplanconf}

% The following \documentclass options may be useful:
%
% 10pt  To set in 10-point type instead of 9-point.
% 11pt  To set in 11-point type instead of 9-point.
% authoryear To obtain author/year citation style instead of numeric.

\usepackage{amsmath}
\usepackage{bbding}
\usepackage{pifont}
\usepackage{url}

\begin{document}

\conferenceinfo{PLATEAU '12}{October 21, Tucson (AZ)} 
\copyrightyear{2012} 
\copyrightdata{[to be supplied]}

%\titlebanner{banner above paper title} % These are ignored unless
%\preprintfooter{short description of paper} % 'preprint' option specified.

\title{Programming Languages vs. Fat Fingers}
\subtitle{An Empirical Study}

\authorinfo{Diomidis Spinellis\and Vassilios Karakoidas}
  {Athens University of Economics and Business}
  {\{dds, bkarak\}@aueb.gr}

\maketitle

\begin{abstract}
We explore how programs written in ten popular programming languages
are affected by small changes of their source code.
This allows us to analyze the extend to which these languages
can detect simple errors at compile or at run time.
Our study is based on a large corpus of programs written in several programming
languages systematically perturbed using a mutation-based fuzz generator.
We found ... % XXX
\end{abstract}

\category{CR-number}{subcategory}{third-level}

\terms
term1, term2

\keywords
Programming Languages, Compiler, Fuzzing, Unit Testing

\section{Introduction} % {{{1
A substitution of a comma with a period in project Mercury's working
{\sc fortran} code compromised the accuracy of the results,
rendering them unsuitable for longer orbital missions \cite{Brad89,Neu95}.
How probable are such events and how does a programming language's
design affect their likelihood and severity?

To study these questions we chose ten popular programming languages,
and a corpus of programs written in all of them.
We then constructed a source code mutation {\em fuzzer}:
a tool that systematically introduces diverse random perturbations
into the program's source code,
and examined whether the resultant source code had errors that
were detected at compile or runtime, and whether it produced
erroneous results.

In practice,
the errors that we artificially introduced into the source code can
crop up in a number of ways.
Mistyping---the ``fat fingers'' syndrome-- is one plausible source.
Other scenarios include
absent-mindedness,
automated refactorings gone awry
(especially in languages where such tasks cannot be reliably implemented),
unintended consequences from complex editor commands or
search-and-replace operations,
and even the odd cat walking over the keyboard.

The contribution of our work is twofold.
First, we describe a method for systematically evaluating the tolerance
of source code written in diverse programming languages to a particular
class of errors.
In addition, we apply this method to numerous tasks written in ten popular
programming languages,
and by analyzing tens of thousands of cases we present an overview of
the likelihood and impact of these errors among diverse languages.

In the remainder of this paper we present our
methods (Section~\ref{sec:method}) and
results (Section~\ref{sec:results}),
we discuss our findings (Section~\ref{sec:discussion}),
compare our approach against related work
(Section~\ref{sec:related}),
and conclude with proposals for further work
(Section~\ref{sec:conclusions}).

\section{Methodology} % {{{1
\label{sec:method}

\begin{table}
\begin{center}
\begin{tabular}{ l l}
Language & Implementation \\
\hline
C 			& gcc 4.4.5 \\
C++ 		& g++ 4.4.5 \\
C\# 		& mono 2.6.7, CLI v2.0 \\
Haskell 	& ghc 6.12.1 \\
Java 		& OpenJDK 1.6.0\_18 \\
Javascript 	& spidermonkey 1.8.0 \\
PHP 		& PHP 5.3.3-7 \\
Perl 		& perl 5.10.1 \\
Python 		& python 2.6.6 \\
Ruby 		& ruby 1.5.8 \\
\end{tabular}
\end{center}
\caption{Tested languages.}
\label{tab:langs}
\end{table}

We selected the languages to test based on a number of sources
collated in an {\sc ieee} Spectrum article \cite{Kin11}:
an index created by
{\sc tiobe}\footnote{\url{http://www.tiobe.com/index.php/content/paperinfo/tpci/index.html}} (a software research firm),
the number of book titles listed on Powell's Books,
references in online discussions on {\sc irc}, and
number of job posts on Craigslist.
From the superset of the popular languages listed in those
sources we excluded
Actionscript, Visual Basic, {\sc sql}, Objective C, and the Unix shell,
because the corresponding programs or infrastructure would not match our methods.
According to the source composition,
our language coverage ranges from 71\% to 86\% of all languages.
The list of the ten languages we used in our study and the
particular implementations we used are listed in
Table~\ref{tab:langs}.

We obtained source code executing the same task in all ten
languages of our study from
{\em Rosetta Code},\footnote{\url{http://rosettacode.org/}}
a so-called programming chrestomathy site,
organized in the form of a wiki.
In the words of its creators,
the site aims is to present code for the same task in as many languages as possible,
thus demonstrating their similarities and differences and
aiding persons with a grounding in one approach to a problem in learning another.
At the time of the writing {\em Rosetta Code}
listed 600 tasks and code in 470 languages.
However, most of the tasks are presented only in a subset of those languages.

\begin{table}
\begin{center}
\begin{tabular}{ l p{5cm}}
Task Name & Description\\
\hline
AccumFactory & A function that takes a number $n$ and returns a function that takes a number $i$,
and returns $n$ incremented by $i$. \\
Beers & Print the ``99 bottles of beer on the wall'' song.\\
Dow & Detects all years in a range in which Christmas falls on a Sunday.\\
FlatList & Flattens a series of nested lists.\\
FuncComp & Implementation of mathematical function composition.\\
Horner & Horner's Method for polynomial evaluation.\\
Hello & A typical ``hello, world!'' program.\\
Mult & Ethiopian Multiplication: a method to multiply integers using only addition, doubling and halving.\\
MutRecursion & Hofstadter's Female and Male sequence~\cite{Hof89}.\\
ManBoy & A test to distinguish compilers that correctly implement
recursion and non-local references from those that do not~\cite{Knu64}.  \\
Power & Calculation of a set's $S$ power set: the set of all subsets of $S$.\\
Substring & Count the occurrences of a substring.\\
Tokenizer & A string tokenizing program.\\
ZigZag & Produce a square arrangement of the first $N^2$ integers,
where the numbers increase sequentially in a zig-zag along the anti-diagonals of the array.\\
\end{tabular}
\end{center}
\caption{List of the selected {\em Rosseta Code} tasks.}
\label{tab:tasks}
\end{table}

We selected our tasks from {\em Rosetta Code} through the following process.
First, we downloaded the listing of all available tasks and
filtered it to create a list of task name {\sc url}s.
We then downloaded the page for each task in MediWiki markup format,
located the headers for the languages in which that task was implemented, and
created a table containing tasks names and language names.
We joined that table with our chosen languages,
thus obtaining a count of the tasks implemented in
most of the languages in our set.
From that set we selected tasks that implemented diverse
non-trivial functionality,
and also, as a test case, the ``Hello, world!'' task.
The tasks we studied are listed in Table~\ref{tab:tasks}.

Fuzzing types

\begin{description}
	\item [IdentifierSubstitution (IdSub)]
	\item [IntegerPerturbation (IntPert)]
	\item [RandomCharacterSubstitution (RandCharSub)]
	\item [RandomTokenSubstitution (RandTokenSub)] Replace one random token with another. This simulates abbsent-mindendness
	\item [SimilarSubstitution (SimSub)]
\end{description}

the fuzzer result is deterministic? Each time we executed the fuzzer to the source, it produces the same permutation of the code?

We measure:

\begin{itemize}
	\item Compilation Success Rate (com): if the a project with the specified fuzzer fails to compile.
	\item Execution Success Rate (run): if the program is executing correctly (without crashing)
	\item Output Validity Success Rate (out): if the program is not producing the proper result
\end{itemize}


\section{Results} % {{{1
\label{sec:results}

\begin{table*}
% ['c', 'cpp', 'cs', 'hs', 'java', 'js', 'php', 'pl', 'py', 'rb']
\begin{center}
\begin{tabular}{l r r r r r r r r r r   r}
 & C & C++ & C\# & Haskell & Java & Javascript & PHP & Perl & Python & Ruby & \textbf{Implemented}\\
 &   &     &     &         &      &            &     &      &        &      &  \textbf{Languages}\\
\hline
AccumFactory & 17 & 57 & 8 & 16 & 16 & 8 & 7 & 7 & 10 & 30 & 10 \\
Hello & 7 & 8 & 7 & 1 & 6 & 1 & 1 & 1 & 7 & 1 & 10 \\
FlatList & 118 & \ding{55} & \ding{55} & 15 & \ding{55} & 4 & 15 & 5 & 14 & 1 & 7 \\
Power & 27 & 77 & \ding{55} & 10 & 31 & 13 & 59 & 3 & 29 & 47 & 9 \\
ZigZag & 22 & 80 & \ding{55} & 19 & 46 & \ding{55} & 31 & 15 & 13 & 14 & 8 \\
FuncComp & 60 & 34 & 18 & 4 & 32 & 6 & 7 & 9 & 3 & 7 & 10 \\
Substring & 21 & 21 & 35 & \ding{55} & 10 & 1 & 3 & 9 & 1 & 1 & 9 \\
ManBoy & 46 & 32 & 22 & 11 & 28 & 8 & 13 & 8 & 11 & 5 & 10 \\
Beers & 14 & 12 & 28 & 6 & 21 & 9 & 14 & 20 & 13 & 12 & 10 \\
Tokenizer & 22 & 15 & 16 & \ding{55} & 11 & 1 & 3 & 1 & 2 & 1 & 9 \\
Horner & 21 & 20 & 15 & 3 & 22 & 3 & 8 & 10 & 6 & 3 & 10 \\
MutRecursion & 29 & 35 & 31 & 8 & 20 & 18 & 22 & 28 & 4 & 8 & 10 \\
Dow & 23 & 17 & 17 & 7 & 13 & 5 & 9 & 17 & 7 & 4 & 10 \\
Mult & 31 & 53 & 61 & 14 & 40 & 25 & 32 & 23 & 41 & 25 & 10 \\
\hline
\textbf{Total lines} & 458 & 461 & 258 & 114 & 296 & 102 & 224 & 156 & 161 & 159 & \\
\end{tabular}
\end{center}
\caption{Lines of Code per Task and per Language, Unimplemented Tasks, and Implemented Languages per Task.}
\label{tbl:lang-compatibility}
\end{table*}

\begin{table*}
\begin{center}
\begin{tabular}{ l r r r r r r r r r r r r r r r r r r }
 & \multicolumn{3}{c}{IdSub (\%)} & \multicolumn{3}{c}{IntPert (\%)} & \multicolumn{3}{c}{RandCharSub (\%)} & \multicolumn{3}{c}{RandTokenSub (\%)} & \multicolumn{3}{c}{SimSub (\%)}\\
           & com  & run  & out  & com   & run  & out   & com  & run  & out  & com  & run  & out  & com  & run  & out\\
\hline
C          & 16.6 & 14.0 & 10.4 & 100.0 & 52.6 & 18.6  & 7.3  & 7.3  & 6.1  & 5.4  & 5.1  & 3.4  & 20.6 & 16.6 & 9.6 \\
C++        & 5.6  & 4.9  & 3.9  & 91.7  & 47.2 & 6.2   & 3.7  & 3.7  & 3.4  & 2.6  & 2.4  & 1.3  & 8.3  & 7.1  & 3.1 \\
C\#        & 6.9  & 6.9  & 6.6  & 69.8  & 65.2 & 11.9  & 4.0  & 4.0  & 3.9  & 3.0  & 3.0  & 2.7  & 7.7  & 7.4  & 6.0 \\
Haskell    & 4.0  & 1.9  & 0.4  & 89.4  & 84.0 & 10.3  & 3.7  & 3.4  & 2.3  & 3.5  & 3.2  & 1.8  & 13.4 & 11.2 & 2.1 \\
Java       & 5.1  & 3.6  & 2.9  & 100.0 & 82.5 & 20.3  & 3.1  & 3.0  & 2.9  & 2.3  & 1.9  & 1.7  & 7.9  & 6.4  & 3.1 \\
Javascript & 65.9 & 18.4 & 5.7  & 100.0 & 79.7 & 6.0   & 30.9 & 9.6  & 7.9  & 15.0 & 5.7  & 1.9  & 57.2 & 22.9 & 5.1 \\
PHP        & 56.4 & 34.1 & 3.0  & 99.2  & 87.5 & 16.2  & 37.4 & 32.7 & 1.9  & 25.7 & 23.7 & 1.1  & 46.2 & 39.7 & 1.4 \\
Perl       & 57.9 & 29.3 & 7.4  & 100.0 & 91.0 & 22.1  & 15.1 & 11.6 & 6.7  & 18.2 & 14.2 & 4.9  & 44.3 & 27.3 & 10.5 \\
Python     & 43.3 & 17.3 & 12.6 & 100.0 & 75.3 & 14.4  & 18.3 & 6.9  & 6.1  & 20.7 & 10.6 & 5.7  & 45.2 & 23.6 & 10.0 \\
Ruby       & 52.3 & 11.8 & 9.1  & 100.0 & 91.1 & 31.6  & 27.6 & 14.7 & 12.3 & 33.4 & 15.8 & 11.1 & 58.0 & 27.0 & 16.1 \\
\hline
\textbf{Mean} & 30.6 & 14.0 & 6.2  & 95.1  & 74.5 & 15.8  & 15.1 & 9.7  & 5.3  & 12.8 & 8.5  & 3.5  & 30.3 & 18.7 & 6.6 \\
\end{tabular}
\end{center}
\caption{Aggregated results per language}
\label{tbl:aggregated-per-language}
\end{table*}

\section{Discussion} % {{{1
\label{sec:discussion}

\section{Related Work} % {{{1
\label{sec:related}

Fuzzing as a technique to investigate the reliability of software
was first proposed in an article by Miller and his colleagues~\cite{MFS90}.

In this paper they tested the common collection of {\sc unix}
utilities in various operating systems and architectures and discrovered that
25-33\% of these, are crashing under certain conditions. To perform these tests
they implemented automation shell scripts and a fuzzer, a program that generated
random character sequences according to certain specifications.

Fuzzing is used mainly to detect software security vulnerabilities and 
improve overall reliability \cite{TJC08,GODE07}. Several tools and techniques \cite{WWGZ11}
have been developed, introducing concept like \textit{directed fuzz testing} \cite{GLRI09}.

Our approach fuzzes the program with pseudo-random
perturbations based in same cases on knowledge of
lexical tokens. This can result in a large number of failures.

An alternative approach, {\em grammar-based white box fuzzing} \cite{God08},
takes into account the input language's grammar to fuzz the input in
ways that are syntactically correct.
This results in a higher rate of successful fuzzing and the location
of deeper problems.

All these approaches are based on the fact that it is practically impossible to detect all
execution paths and all program inputs to fully test the validity and the reliability of a program.

Random Testing \cite{HAM06} seems to be the only solution that can partially deal with this problem,
but still it is not widely adopted outside the academic fields \cite{GGBO07}, since the techniques it 
introduces are difficult to be applied in complex systems and achieve good code coverage, if so at a significant cost \cite{RAWO06}.

The above case is made worse with the use of complex refactorings \cite{Fow00} in day-to-day programming. Refactorings are beneficial, but they are programs integrated in {\sc ide}s and also have bugs \cite{DDGM07}. Every bug results in corrupted code, which is very difficult to detect, especially for the case of dynamic langugages \cite{SCHA12,FFM+11}.

Our experiment aims to exhibit the fault tolerance \cite{LYU95,KOKR07} of each language and use their features such as 
their type systems to our advantage. 

Type systems are usually realized as type checkers in compilers and linkers of programming languages. They are categorized as static and dynamic. \textit{Static typing} implies static type checking. In other words, the ability of a programming language's compiler to know all the data types that are used in a program, and guarantee that they are correct at compile time. \textit{Dynamic typing} is exactly the opposite. The languages that are dynamically checked perform run-time checks in order to ensure consistent type use. 

In addition, a programming language is called safe, when it protects its own abstractions. For example, a programming language that provides an abstraction for arrays, is considered safe, if it performs boundary checking upon access. Consequently, Java is a statically checked and safe programming language, while C/C++ are statically checked and unsafe. On the other hand, Perl and Lisp are dynamically checked and safe \cite{Pie02}.

Statically typed languages are less tolerant to our approach, since the compiler catches all syntax or type errors and fail the compilation process. Dynamic languages like python, perl and ruby are more tolerant and usually they fail upon execution or produce corrupted output.

\section{Conclusions} % {{{1
\label{sec:conclusions}


\acks

We would like to thank Florents Tselai for significant
help in the porting and implementation of the
{\em Rosetta Code} tasks in our environment.

% XXX STEREO

% We recommend abbrvnat bibliography style.

\bibliographystyle{abbrvnat}
\bibliography{fuzzer}

% The bibliography should be embedded for final submission.

%\begin{thebibliography}{}
%\softraggedright

%\bibitem[Smith et~al.(2009)Smith, Jones]{smith02}
%P. Q. Smith, and X. Y. Jones. ...reference text...

%\end{thebibliography}

\end{document}
